{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how natural language statistics work on real data. We construct a vocabulary based on the time machine data and print the top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "import torch\n",
    "import random\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = utils.tokenize(utils.read_time_machine())\n",
    "vocab = utils.Vocab(tokens)\n",
    "print(vocab.token_freqs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the most popular words are actually quite boring to look at. They are often referred to as ``stop words`` and thus filtered out. That said, they still carry meaning and we will use them nonetheless. However, one thins that is quite clear is that the word frequency decays rather rapidly. The 10th word is less than 1/5 common as the most popular one. To get a better idea we plot the graph of word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [freq for token, freq in vocab.token_freqs]\n",
    "d2l.plot(freqs, xlabel='token', ylabel='frequency',\n",
    "        xscale='log', yscale='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about word pairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_tokens = [[pair for pair in zip(line[:-1], line[1:])]\n",
    "                 for line in tokens]\n",
    "bigram_vocab = utils.Vocab(bigram_tokens)\n",
    "print(bigram_vocab.token_freqs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 10 most frequent word pairs, 9 are composed of stop words and only one is relevant to the actual book. Let's see the trigram tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_tokens = [[triple for triple in \n",
    "                   zip(line[:-2], line[1:-1], line[2:])]\n",
    "                 for line in tokens]\n",
    "trigram_vocab = utils.Vocab(trigram_tokens)\n",
    "print(trigram_vocab.token_freqs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, let's visualize the token frequencies among these three gram models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_freqs = [freq for token, freq in bigram_vocab.token_freqs]\n",
    "trigram_freqs = [freq for token, freq in trigram_vocab.token_freqs]\n",
    "d2l.plot([freqs, bigram_freqs, trigram_freqs], xlabel='token',\n",
    "          ylabel='frequency', xscale='log', yscale='log',\n",
    "          legend=['unigram', 'bigram', 'trigram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
