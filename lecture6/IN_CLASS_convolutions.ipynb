{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cross-correlation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    H, W = X.shape\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros(H-h+1, W-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your function\n",
    "X = torch.tensor([[0, 1, 2],\n",
    "                 [3, 4, 5],\n",
    "                 [6, 7, 8]]).type(torch.FloatTensor)\n",
    "K = torch.tensor([[0, 1],\n",
    "                 [2, 3]]).type(torch.FloatTensor)\n",
    "\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolutional layer cross-correlates the input and kernels and adds a scalar bias to produce an output.\n",
    "The parameters of the convolutional layer are precisely the values that constitute the kernel and the scalar\n",
    "bias. When training the models based on convolutional layers, we typically initialize the kernels randomly,\n",
    "just as we would with a fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # insert your code here\n",
    "class Conv2D(torch.nn.Module):\n",
    "    def __init__(self, kernel_size, **kargs):\n",
    "        super(Conv2D, self).__init__(**kargs)\n",
    "        self.weight = torch.nn.Parameter(torch.randn(kernel_size),\n",
    "                                        requires_grad=True)\n",
    "        self.bias = torch.nn.Parameter(torch.randn((1,)),\n",
    "                                      requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test\n",
    "my_cnn = Conv2D((2, 2))\n",
    "out = my_cnn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection in Images\n",
    "\n",
    "Let’s look at a simple application of a convolutional layer: detecting the edge of an object in an image by\n",
    "finding the location of the pixel change. First, we construct an 'image' of 6 x 8 pixels. The middle four\n",
    "columns are black (0) and the rest are white (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X\n",
    "X = torch.ones((6, 8)).type(torch.FloatTensor)\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we construct a kernel K with a height of 1 and width of 2. When we perform the cross-correlation\n",
    "operation with the input, if the horizontally adjacent elements are the same, the output is 0. Otherwise, the\n",
    "output is non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Kernel\n",
    "K = torch.tensor([[1, -1]]).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter X and our designed kernel K to perform the cross-correlation operations. As you can see, we will detect\n",
    "1 for the edge from white to black and -1 for the edge from black to white. The rest of the outputs are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output\n",
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s apply the kernel to the transposed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "corr2d(X.T, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning a Kernel\n",
    "\n",
    "Designing an edge detector by finite differences [1, -1] is neat if we know this is precisely what we are\n",
    "looking for. However, as we look at larger kernels, and consider successive layers of convolutions, it might\n",
    "be impossible to specify precisely what each filter should be doing manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s see whether we can learn the kernel that generated Y from X by looking at the (input, output)\n",
    "pairs only. We first construct a convolutional layer and initialize its kernel as a random array. Next, in\n",
    "each iteration, we will use the squared error to compare Y and the output of the convolutional layer, then\n",
    "calculate the gradient to update the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "K = torch.tensor([[1, -1]]).type(torch.FloatTensor)\n",
    "Y = corr2d(X, K)\n",
    "\n",
    "my_net = Conv2D((1, 2))\n",
    "optimizer = torch.optim.SGD(my_net.parameters(),\n",
    "                           lr=0.01)\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = my_net(X)\n",
    "    l = ((Y_hat - Y)**2).sum()\n",
    "    print(\"Error is\", float(l))\n",
    "    optimizer.zero_grad()\n",
    "    l.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the error has dropped to a small value after 10 iterations. Now we will take a look at the kernel array we learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the learned weights\n",
    "my_net.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the learned kernel array is remarkably close to the kernel array K we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
